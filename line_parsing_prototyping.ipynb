{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Parsing Prototyping Notebook\n",
    "\n",
    "This notebook is scrapwork related to line parsing function development. All functions developed here will be rolled into `parse.py` as completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                    # Data handling\n",
    "import numpy as np                     # Math utilities\n",
    "import string                          # String utilities\n",
    "import json                            # JSON handling\n",
    "import re                              # Regular expressions\n",
    "from bs4 import BeautifulSoup as soup  # BeautifulSoup object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPTS = './scripts/{}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Script(object):\n",
    "    \n",
    "    def __init__(self, file):    \n",
    "        with open(SCRIPTS.format(file)) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        self.data = str(soup(data['script'], \"lxml\").find_all(\"pre\")[-1])\n",
    "        self.df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens = Script('Aliens.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.Series(aliens.data.split(sep='\\n'), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component function definitions\n",
    "* **setup_metrics** = creates dictionary for line metric recording\n",
    "* **setup_data** = creates dictionary for line data recording\n",
    "* **update_metric** = updates line metrics based on character data\n",
    "* **update_data** = updates line data based on character data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import L1\n",
    "\n",
    "test = L1.Line()\n",
    "vars(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set line sample for testing\n",
    "sample = (28, lines[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack sample to simulate enumerate loop\n",
    "i, x = sample\n",
    "# Setting basic info and data\n",
    "test.data['raw'] = x\n",
    "test.metrics['id'] = i + .1\n",
    "test.links['L1'] = test.metrics['id']\n",
    "test.metrics['length'] = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'fmt' string\n",
    "temp = x\n",
    "tags = ['<pre>', '</pre>', '<b>', '</b>']\n",
    "for tag in tags:\n",
    "    if tag in x:\n",
    "        temp = temp.replace(tag, '')\n",
    "test.data['fmt'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bold checking\n",
    "if L1.B_OPEN.match(x) != None:  # Open tag check\n",
    "    test.metrics['bold']['open'] = True\n",
    "    test.metrics['bold']['bolded'] = (L1.B_OPEN.match(x).end(), len(x))\n",
    "    test.metrics['bold']['has'] = True\n",
    "    \n",
    "if L1.B_CLOSE.match(x) != None:  # Close tag check\n",
    "    test.metrics['bold']['close'] = True\n",
    "    if test.metrics['bold']['bolded'] == None:  # Check if 'bolded' already set\n",
    "        test.metrics['bold']['bolded'] = (0, L1.B_CLOSE.match(x).start())\n",
    "        if test.metrics['bold']['bolded'][1] - test.metrics['bold']['bolded'][0] != 0:\n",
    "            test.metrics['bold']['has'] = True\n",
    "    else:\n",
    "        test.metrics['bold']['bolded'][1] = L1.B_CLOSE.match(x).start()\n",
    "\n",
    "# Set remaining metrics\n",
    "test.metrics['bold']['num'] = test.metrics['bold']['bolded'][1] - test.metrics['bold']['bolded'][0]\n",
    "test.metrics['bold']['pct'] = test.metrics['bold']['num']/test.metrics['length']\n",
    "test.metrics['bold']['p80'] = test.metrics['bold']['num']/80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Char loop parsing sequence\n",
    "temp_map = ''   # Map string container\n",
    "temp_pnc = {}   # Punctuation string container\n",
    "temp_rgx = r''  # Regex string container\n",
    "temp_spc = []   # Spacing list container\n",
    "prev_c = None   # Stores previous character for comparison\n",
    "html = False    # Flag to track if in html tag\n",
    "\n",
    "for c in x:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = re.compile(r'[\\!-/<-@\\[-`\\{-~]')\n",
    "print(punc.findall(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing routine testing\n",
    "1. Create lines from raw text\n",
    "2. Feed lines into line parsing loop -> `for i,x in enumerate(lines)`\n",
    "    3. Initiate `metrics` dictionary values -> `setup_metrics()`\n",
    "    4. Initiate `data` dictionary values -> `setup_data()`\n",
    "    5. Check if string is empty -> `check_empty()`\n",
    "    6. Check if string is bolded -> `check_bold()`\n",
    "    7. Pass chars to char parsing loop\n",
    "        8. Record bold status -> `log_bold()`\n",
    "        9. Use helper function to check char type -> `check_char()`\n",
    "            10. Record space info -> `log_space()`\n",
    "            11. Record punc info -> `log_punc()`\n",
    "            12. Record num info -> `log_num()`\n",
    "            13. Record char info -> `log_char()`\n",
    "                14. Record upper info -> `log_upper()`\n",
    "                15. Record lower info -> `log_lower()`\n",
    "    16. Update `data` as necessary\n",
    "17. Aggregate metrics in `df`\n",
    "18. Extract metadata info and add to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
